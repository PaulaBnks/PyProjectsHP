from google.cloud import bigquery
from google.oauth2 import service_account
import google.generativeai as genai
from datetime import datetime, timedelta
import numpy as np
from bs4 import BeautifulSoup
import re

# --- CONFIGURATION ---
ACCOUNT_ID = "00109000013HoXkAAK"  # Replace with your test account ID
PROJECT_ID = "southern-coda-233109"
DATASET_ID = "import"
TABLE_ID = "salesforce_embeddings"

# --- AUTHENTICATION ---
print("üîê Loading credentials...")
credentials = service_account.Credentials.from_service_account_file(
    r"E:\Software\python-project-403413-480829366e0a.json"
)
bq_client = bigquery.Client(project=PROJECT_ID, credentials=credentials)
print("‚úÖ BigQuery login successful.")

# Authenticate Gemini
print("üîê Loading Gemini API key...")
with open(r"E:\Software\gemini_prod_key.txt", "r") as file:
    api_key = file.read().strip()
genai.configure(api_key=api_key)
model = genai.GenerativeModel("gemini-2.0-flash")
print("‚úÖ Gemini model initialized.")


# --- HELPER FUNCTIONS ---

def strip_html(text):
    """Remove HTML tags and decode HTML entities."""
    if not text:
        return ""
    soup = BeautifulSoup(text, "html.parser")
    clean_text = soup.get_text(separator=" ")
    clean_text = re.sub(r'\s+', ' ', clean_text).strip()
    return clean_text


def get_embeddings_for_account(account_id, days=365*2):  # Default: last 2 years
    """Fetch all note embeddings + raw text + created_date for an account"""
    cutoff_date = datetime.now() - timedelta(days=days)
    cutoff_str = cutoff_date.strftime("%Y-%m-%d")

    query = f"""
        SELECT id, raw_text, embedding, created_date 
        FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`
        WHERE account_id = '{account_id}'
          AND created_date >= '{cutoff_str}'
        ORDER BY created_date DESC
    """
    rows = bq_client.query(query).result()
    print(f"üß† Loaded {rows.total_rows} notes for account {account_id}")
    return [(row.id, strip_html(row.raw_text), row.embedding, row.created_date) for row in rows]


def get_query_embedding(question):
    """Generate embedding for a question/query"""
    result = genai.embed_content(
        model="models/embedding-001",
        content=question,
        task_type="retrieval_query"
    )
    return result["embedding"]


def cosine_similarity(vec1, vec2):
    """Compute cosine similarity between two vectors"""
    v1 = np.array(vec1)
    v2 = np.array(vec2)
    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))


def find_most_relevant_note(query_embedding, embeddings_data, decay_factor=0.95):
    """Find top 3 most similar notes based on hybrid score (semantic + recency)"""
    similarities = []
    now = datetime.now()

    for version_id, raw_text, embedding, created_date in embeddings_data:
        if len(embedding) != len(query_embedding):
            continue

        sim = cosine_similarity(query_embedding, embedding)

        # Apply time-based weighting
        try:
            note_date = datetime.strptime(created_date, "%Y-%m-%d %H:%M:%S")
            days_old = (now - note_date).days
            time_weight = max(0.1, decay_factor ** days_old)
            weighted_score = sim * time_weight
        except Exception:
            weighted_score = sim

        similarities.append((weighted_score, raw_text[:1000]))  # Limit context size

    similarities.sort(reverse=True, key=lambda x: x[0])
    return similarities[:3]  # Top 3 matches


def ask_question_with_context(question, relevant_notes):
    """Ask Gemini a question using only the most relevant note snippets"""

    context_block = "\n".join([f"{text}" for _, text in relevant_notes])

    full_prompt = f"""
        Du bist ein hilfreicher Assistent f√ºr Salesforce-Vertriebsmitarbeiter bei Cosuno.
        Deine Aufgabe ist es, die folgende Frage basierend auf den bereitgestellten Meetingnotizen zu beantworten.

        ### Frage:
        {question}

        ### Relevanteste Notizen:
        {context_block}

        ### Anweisungen:
        - Beantworte die Frage nur basierend auf den obigen Notizen.
        - Falls keine Note die Antwort enth√§lt, antworte mit: "(Keine relevante Info gefunden)"
        - Halte deine Antwort pr√§gnant und direkt.
        - Priorisiere aktuelle Notizen √ºber √§ltere, sofern sie nicht entscheidend sind.
        
        ### Antwort im gew√ºnschten Format:
        Beginne immer mit:
        #### üîç Gemini Antwort:
        Danach gib deine Antwort aus.

        Beispiel:
        #### üîç Gemini Antwort:
        Die Hauptentscheidungstr√§ger sind Stefan Meier (CFO) und Anna Schmidt (Leiterin Einkauf).
    """

    try:
        response = model.generate_content(full_prompt)
        candidate = response.candidates[0].content.parts[0].text.strip()

        # Extract just the part after "#### üîç Gemini Antwort:"
        match = re.search(r"#### üîç Gemini Antwort:\s*(.*)", candidate, re.DOTALL)
        return match.group(1).strip() if match else candidate

    except Exception as e:
        return f"[Error]: {e}"


# --- MAIN TESTING LOGIC ---

print(f"\nüß† Fetching embeddings for Account: {ACCOUNT_ID}")
embeddings_data = get_embeddings_for_account(ACCOUNT_ID)

if not embeddings_data:
    print("‚ö†Ô∏è No embeddings found for this account.")
else:
    print(f"‚úÖ Found {len(embeddings_data)} embedded notes.\n")

    # Define test questions
    questions = {
        "Was sind die wichtigsten Erkenntnisse?": "1. Key Takeaways",
        "Welche n√§chsten Schritte wurden besprochen?": "2. Action Items",
        "Wer sind die Entscheidungstr√§ger?": "6. Decision Makers",
        "Welche Probleme wurden erw√§hnt?": "4. Pain Points",
        "Wie sieht der Ausschreibungsprozess aus?": "Current Tendering Process",
        "Wie l√§uft der Entscheidungsprozess ab?": "5. Decision Process",
        "Was ist das Unternehmensprofil?": "3. Background"
    }

    # Ask each question and show results
    for question, section in questions.items():
        print(f"\n{'-'*50}\n")
        print(f"üìå Section: {section}")
        print(f"‚ùì Frage: {question}")

        query_emb = get_query_embedding(question)
        relevant_notes = find_most_relevant_note(query_emb, embeddings_data)

        answer = ask_question_with_context(question, relevant_notes)
        print(f"üß† Gemini Antwort: {answer}")

        print("\nüìé Verwendete Notizen:")
        for idx, (sim, text) in enumerate(relevant_notes):
            print(f"\nNote {idx+1} (Bewertung: {sim:.4f})\n{text[:200]}...")
